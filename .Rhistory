install.packages("RStata")
### Parallelized version of After_Hwang_v3_MonteCarlo.R using multivariate regressors
### check whether increasing sample size gives converging estimates to population bounds
#install.packages("splines")
#install.packages("quantreg")
#install.packages("pracma")
#install.packages("cubature")
#install.packages("foreach")
#install.packages("doParallel")
#install.packages("cde")
#install.packages("np")
#install.packages("McSpatial")
#install.packages("MASS")
#install.packages("emdbook")
library(splines)   # Libraries
library(quantreg)
library(pracma)
library(cubature)
library(foreach)                                                                # Parallel Implementation of Boostrap Calculations
library(doParallel)
library(cde)
library(np)
library(McSpatial)
library(MASS)
library(emdbook)
samsize <- c(6000)
beta    <- c(0,1,1,1)
gamma   <- c(0,1,1)
mu      <- c(0,0,0,0)
sigma   <- eye(4)
# mu and sigma for vector (w1,w2,x,y)
A <- rbind( c(1,0,0,0), c(0,1,0,0), c(gamma[2],gamma[3],1,0), c(beta[3]+beta[2]*gamma[2],beta[4]+beta[2]*gamma[3], beta[2],1))
B <- c(0,0,gamma[1],beta[1])
mu2    <- A%*%mu + B
sigma2 <- A%*%sigma%*%t(A)
mu2
sigma2
A
gamma
beta
install.packages(c("broom", "ggthemes", "mapproj", "maps", "readstata13", "sf", "socviz", "tidycensus", "tidyverse", "tigris", "usmap"))
install.packages(c("broom", "ggthemes", "mapproj", "maps", "readstata13", "sf", "socviz", "tidycensus", "tidyverse", "tigris", "usmap"))
install.packages(c("broom", "ggthemes", "mapproj", "maps", "readstata13", "sf", "socviz", "tidycensus", "tidyverse", "tigris", "usmap"))
install.packages(c("broom", "ggthemes", "mapproj", "maps", "readstata13", "sf", "socviz", "tidycensus", "tidyverse", "tigris", "usmap"))
devtools::install_github("hrbrmstr/albersusa")
library(albersusa)
devtools::install_github("ropensci/USAboundariesData")
rm(list=ls()) # clean memory
#setwd("/Users/denghuan/Downloads/covid19")
library(tidyverse)
library(socviz) # to draw maps wihout discarding Alaska
library(maps)
library(mapproj)
library(tigris)
library(tidycensus)
library(sf)
library(broom)
library(viridis)
library(USAboundariesData)
library(usmap)
#devtools::install_github("hrbrmstr/albersusa")
#devtools::install_github("ropensci/USAboundariesData")
library(ggthemes)
library(albersusa)
library(copula)
cop <- gumbleCopula(200)
cop <- gumbelCopula(200)
contourplot2(cop,dCopula)
contourplot2(cop,pCopula)
cop <- gumbelCopula(1)
cop <- gumbelCopula(2)
contourplot2(cop,dCopula)
cop <- gumbelCopula(100)
contourplot2(cop,dCopula)
cop <- claytonCopula(2)
contourplot2(cop,dCopula)
cop <- frankCopula(2)
contourplot2(cop,dCopula)
cop <- gumbelCopula(100)
contourplot2(cop,dCopula)
cop <- gumbelCopula(500)
contourplot2(cop,dCopula)
cop <- gumbelCopula(200)
contourplot2(cop,dCopula)
load("~/Dropbox/Document/AntiAsian Racism/Data/Pilot Survey/data/DistParam.RData")
# load libraries
# install these packages if you haven't
library(gmailr)
library(googlesheets4)
### set a directory for a Gmail Client ID json file
FILEDIR="/Users/yujung/Dropbox/Document/GoogleAPI/"
### set a filename for the json file
FILENAME="gmailr.json"
# configure Gmail API
gm_auth_configure(path=paste0(FILEDIR,FILENAME))
### read seminar schedule info (CHANGE THE SPREADSHEET LINK BELOW)
seminar_schedule_link <- "https://docs.google.com/spreadsheets/d/1TVZpmKuRcB2IbOgfgtGQvebvVEMMS8LoNHuEvh30EU8/edit#gid=0"
seminar_schedule <- read_sheet(seminar_schedule_link)
# compute the days until the next seminar
daysleft <- as.Date(seminar_schedule$Date) - Sys.Date()
ind <- which(daysleft>=0)[1]
### retrieve the next speaker information
### seminar speaker name
speaker_name =seminar_schedule$Speaker[ind]
### speaker email
speaker_email =seminar_schedule$Email[ind]
### speaker institution
speaker_institution =seminar_schedule$Institution[ind]
### paper title
paper_title =seminar_schedule$Paper[ind]
### seminar date and time
seminar_date=seminar_schedule$Date[ind]
seminar_time=seminar_schedule$Time[ind]
### Set organizer / audience information
### Organizer first name
organizer_name="Yujung"
### Organizer email address
organizer_email ="yujungghwang@gmail.com"
### Audience email
audience_email ="yujungghwang@gmail.com"
### Zoom link for the seminar
zoom_link="https://zoom.us/my/yhwang"
### sign up information
signup_link ="https://docs.google.com/spreadsheets/d/11HCLZPHPx0j0ILhy3w8u5QAiPk1SD8paJdbgVzPJSm0/edit#gid=0"
grad_signup_time ="Monday 10AM"
# load libraries
# install these packages if you haven't
library(gmailr)
library(googlesheets4)
### set a directory for a Gmail Client ID json file
FILEDIR="/Users/yujung/Dropbox/Document/GoogleAPI/"
### set a filename for the json file
FILENAME="gmailr.json"
# configure Gmail API
gm_auth_configure(path=paste0(FILEDIR,FILENAME))
### read seminar schedule info (CHANGE THE SPREADSHEET LINK BELOW)
seminar_schedule_link <- "https://docs.google.com/spreadsheets/d/1TVZpmKuRcB2IbOgfgtGQvebvVEMMS8LoNHuEvh30EU8/edit#gid=0"
seminar_schedule <- read_sheet(seminar_schedule_link)
# compute the days until the next seminar
daysleft <- as.Date(seminar_schedule$Date) - Sys.Date()
ind <- which(daysleft>=0)[1]
### retrieve the next speaker information
### seminar speaker name
speaker_name =seminar_schedule$Speaker[ind]
### speaker email
speaker_email =seminar_schedule$Email[ind]
### speaker institution
speaker_institution =seminar_schedule$Institution[ind]
### paper title
paper_title =seminar_schedule$Paper[ind]
### seminar date and time
seminar_date=seminar_schedule$Date[ind]
seminar_time=seminar_schedule$Time[ind]
### Set organizer / audience information
### Organizer first name
organizer_name="Yujung"
### Organizer email address
organizer_email ="yujungghwang@gmail.com"
### Audience email
audience_email ="yujungghwang@gmail.com"
### Zoom link for the seminar
zoom_link="https://zoom.us/my/yhwang"
### sign up information
signup_link ="https://docs.google.com/spreadsheets/d/11HCLZPHPx0j0ILhy3w8u5QAiPk1SD8paJdbgVzPJSm0/edit#gid=0"
grad_signup_time ="Monday 10AM"
# email to a seminar speaker to ask a paper title / paper copy
# first check if there is any seminar scheduled within the next 10 days & if paper title is empty
source("setGmailConfig.R")
daysleft[ind]
seminar_schedule
is.null(seminar_schedule$PaperTitle[ind])
is.na(seminar_schedule$PaperTitle[ind])
help(range_clear)
# update the sign up sheet to blank page
range_clear(signup_link,range="B3:B12")
range_clear(signup_link,range="A1")
range_write(signup_link,data=paste0(speaker_name," sign up"),range="A1")
speaker_name
range_write(signup_link,data=as.data.frame(paste0(speaker_name," sign up")),range="A1")
range_write(signup_link,data=as.data.frame(x=paste0(speaker_name," sign up")),range="A1")
as.data.frame(paste0(speaker_name," sign up"))
range_write(signup_link,data=as.data.frame(paste0(speaker_name," sign up"))[1,1],range="A1")
as.data.frame(paste0(speaker_name," sign up"))
signuphead=as.data.frame(paste0(speaker_name," sign up"))
colnames(signuphead)=NULL
signuphead
range_write(signup_link,data=signuphead,range="A1")
seminar_date
signuphead=as.data.frame(a1=paste0(speaker_name," sign up"),a2=paste0("Date : ",seminar_date))
colnames(signuphead)=NULL
range_write(signup_link,data=signuphead,range="A1")
signuphead=as.data.frame(x=paste0(speaker_name," sign up"),y=paste0("Date : ",seminar_date))
signuphead
signuphead=as.data.frame(cbind(paste0(speaker_name," sign up"),paste0("Date : ",seminar_date)))
signuphead
colnames(signuphead)=NULL
range_write(signup_link,data=signuphead,range="A1")
Sys.time()
format(Sys.time())
Sys.getenv("R_HOME")
library(bndovb)
data(maindat_nome)
data(auxdat_nome)
bndovb(maindat=maindat_nome,auxdat=auxdat_nome,depvar="y",ovar="x1",comvar=c("x2","x3"),method=1)
data(maindat_mecont)
data(auxdat_mecont)
pvar<-c("z1","z2","z3")
cvar<-c("x","w1")
bndovbme(maindat=maindat_mecont,auxdat=auxdat_mecont,depvar="y",pvar=pvar,ptype=1,comvar=cvar)
data(maindat_medisc)
data(auxdat_medisc)
bndovbme(maindat=maindat_medisc,auxdat=auxdat_medisc,depvar="y",pvar=pvar,ptype=2,comvar=cvar)
library(bndovb)
bndovbme
## load example data
data(maindat_mecont)
data(auxdat_mecont)
## set ptype=1 for continuous proxy variables
pvar<-c("z1","z2","z3")
cvar<-c("x","w1")
ptm <- proc.time()
oout1 <- bndovbme(maindat=maindat_mecont,auxdat=auxdat_mecont,depvar="y",pvar=pvar,ptype=1,comvar=cvar,ngrid=3)
print(oout1)
proc.time()-ptm
ptm <- proc.time()
oout2 <- bndovbme(maindat=maindat_mecont,auxdat=auxdat_mecont,depvar="y",pvar=pvar,ptype=1,comvar=cvar,ngrid=Inf)
print(oout2)
proc.time()-ptm
maindat=maindat_mecont;auxdat=auxdat_mecont;depvar="y";pvar=pvar;ptype=1;comvar=cvar;ngrid=Inf
sbar=2;coefub=100;coeflb=-100;ngrid=3;mainweights=NULL;auxweights=NULL
#############
# check if inputs are there in a correct form
#############
if (!is.matrix(maindat) & !is.data.frame(maindat)){
stop("please provide main data in either matrix or data frame format.")
}
if (!is.matrix(auxdat) & !is.data.frame(auxdat)){
stop("please provide auxiliary data in either matrix or data frame format.")
}
# check if column names of auxiliary data exists
if (is.null(colnames(auxdat))){
stop("column names of auxiliary data do not exist.")
}
# check if column names of main data exists
if (is.null(colnames(maindat))){
stop("column names of main data do not exist.")
}
# check if auxiliary dataset includes every independent regressor
if ((sum(comvar%in%colnames(auxdat))<length(comvar)) | (sum(pvar%in%colnames(auxdat))<length(pvar)) ){
stop("auxiliary dataset does not contain every right-hand side regressor.")
}
# check if main dataset includes every independent regressor
if (sum(comvar%in%colnames(maindat))<length(comvar)){
stop("main dataset does not contain every common right-hand side regressor.")
}
# check if main dataset includes dependent variable
if (!(depvar%in%colnames(maindat))){
stop("main dataset does not include the dependent variable.")
}
# check if the proxy variable type is correctly specified
if (!(ptype%in%c(1,2))){
stop("Incorrect type was specified for proxy variables. ptype should be either 1 or 2.")
}
# check if there are enough proxy variables
if ((ptype==1) & (length(pvar)<2)){
stop("There are insufficient number of proxy variables. There must be at least 2 proxy variables when the omitted variable is continuous.")
}
if ((ptype==2) & (length(pvar)<3)){
stop("There are insufficient number of proxy variables. There must be at least 3 proxy variables when the omitted variable is discrete.")
}
if (!is.null(mainweights)){
# check if the weight vector for main data has a correct length
if (length(mainweights)!=dim(maindat)[1]){
stop("Incorrect length for the main data weight vector. The length must be equal to the number of rows of 'maindat'.")
}
# check if any weight vector includes NA or NaN or Inf
if (sum(is.na(mainweights))>0|sum(is.nan(mainweights))>0|sum(is.infinite(mainweights))>0){
stop("mainweights vector can not include any NAs or NaNs or Infs.")
}
}
if (!is.null(auxweights)){
# check if the weight vector for auxiliary data has a correct length
if (length(auxweights)!=dim(auxdat)[1]){
stop("Incorrect length for the auxiliary data weight vector. The length must be equal to the number of rows of 'auxdat'.")
}
# check if any weight vector includes NA or NaN or Inf
if (sum(is.na(auxweights))>0|sum(is.nan(auxweights))>0|sum(is.infinite(auxweights))>0){
stop("auxweights vector can not include any NAs or NaNs or Infs.")
}
}
#############
# prepare data in a right form
#############
# number of observations
Nm <- dim(maindat)[1]
Na <- dim(auxdat)[1]
# add 1 vector
comvar <- c(comvar,"con")
maindat$con <- rep(1,Nm)
auxdat$con <- rep(1,Na)
# leave only necessary variables and make the order of variables consistent
maindat <- maindat[,c(depvar,comvar)]
auxdat <- auxdat[,c(pvar,comvar)]
# number of regressors in a regrssion model (assuming there is only one omitted variable)
nr <- length(comvar)+1
#############
# estimate CDF and Quantile function
#############
# estimate N(depvar | comvar)
f1 <- paste0(depvar,"~ 0 +",comvar[1])
if (length(comvar)>1){
for (k in 2:length(comvar)){
f1 <- paste0(f1,"+",comvar[k])
}
}
if (is.null(mainweights)){
oout1 <- lm(formula=f1,data=maindat) ## regression without intercept because of "con" in "comvar"
} else{
oout1 <- lm(formula=f1,data=maindat,weights=mainweights) ## regression without intercept because of "con" in "comvar"
}
Fypar <- matrix(oout1$coefficients,ncol=1)
yhat  <- as.matrix(maindat[,comvar])%*%Fypar
ysd   <- sd(oout1$residuals,na.rm=TRUE)
# continuous proxy variables
if (is.null(auxweights)){
pout <- cproxyme(dat=auxdat[,pvar],anchor=1)
} else{
pout <- cproxyme(dat=auxdat[,pvar],anchor=1,weights=auxweights)
}
alpha0   <- pout$alpha0
alpha1   <- pout$alpha1
varnu    <- pout$varnu
mtheta   <- pout$mtheta
vartheta <- pout$vartheta
N <- dim(auxdat)[1]
nc <- length(comvar)
library(factormodel)
if (is.null(auxweights)){
pout <- cproxyme(dat=auxdat[,pvar],anchor=1)
} else{
pout <- cproxyme(dat=auxdat[,pvar],anchor=1,weights=auxweights)
}
alpha0   <- pout$alpha0
alpha1   <- pout$alpha1
varnu    <- pout$varnu
mtheta   <- pout$mtheta
vartheta <- pout$vartheta
N <- dim(auxdat)[1]
nc <- length(comvar)
# construct normalized proxy variables
npdat  <- auxdat[,pvar]
np <- length(pvar)
nsdnu <- rep(NA,np)
for (i in 1:np){
npdat[,i] <- (npdat[,i]-alpha0[i])/alpha1[i]
nsdnu[i]  <- sqrt(varnu[i]/(alpha1[i]^2))
}
ngrid
# discretize the distribution of measurement errors
if (!is.infinite(ngrid)){
# discretize the distribution of measurement errors of proxy variables
dmedist <- list()
for (g in 1:np){
# discretize a distribution with ngrid points with equal probability
dmedist[[g]] <- discretizeNormDist(n=ngrid,mean=0,var=(nsdnu[g]^2))
}
}
demist
dmedist
## likelihood if ngrid<Inf
Plike1 <- function(param,cdat,npdat,nsdnu,nc,N,medist,weights=NULL){
Fopar <- matrix(param[1:nc],ncol=1)
osd <- abs(param[(nc+1)]) # positive value
mmu <- as.matrix(cdat)%*%Fopar
### integration using discretized measurement error distribution
pdffun <- function(zz,muo,medist,ngrid) {
return(mean(dnorm(zz-medist,mean=muo,sd=osd)))
}
ll <- rep(0,N)
for (i in 1:N){
if (sum(is.na(npdat[i,]))==np){
# every proxy is missing
ll[i] <- NA
} else{
# convolution
for (k in 1:np){
if (!is.na(npdat[i,k])){
ll[i] <- ll[i] + log(pdffun(zz=npdat[i,k],muo=mmu[i],medist=medist[[k]],ngrid=ngrid))
}
}
if (is.infinite(ll[i])){
ll[i] <- -10^(-323) ### lowest number
}
}
}
if (!is.null(weights)){
ll <- ll*weights
}
ll <- ll[!is.na(ll) & !is.nan(ll)]
return(ll)
}
## likelihood if ngrid=Inf
Plike1_inf <- function(param,cdat,npdat,nsdnu,nc,N,weights=NULL){
Fopar <- matrix(param[1:nc],ncol=1)
osd <- abs(param[(nc+1)]) # positive value
mmu <- as.matrix(cdat)%*%Fopar
### convolution of two normals
pdffun_inf <- function(zz,muo,nsdnu) integrate(function(eps,zz,muo,nsdnu) dnorm(zz-eps,mean=muo,sd=osd)*dnorm(eps,mean=0,sd=nsdnu),-Inf,Inf,zz=zz,muo=muo,nsdnu=nsdnu,stop.on.error=FALSE)$value
ll <- rep(0,N)
for (i in 1:N){
if (sum(is.na(npdat[i,]))==np){
# every proxy is missing
ll[i] <- NA
} else{
# convolution
for (k in 1:np){
if (!is.na(npdat[i,k])){
ll[i] <- ll[i] + log(pdffun_inf(zz=npdat[i,k],muo=mmu[i],nsdnu=nsdnu[k]))
}
}
if (is.infinite(ll[i])){
ll[i] <- -10^(-323) ### lowest number
}
}
}
if (!is.null(weights)){
ll <- ll*weights
}
ll <- ll[!is.na(ll) & !is.nan(ll)]
return(ll)
}
getwd()
getwd("/Users/yujung/Dropbox/Document/GitHub/bndovb/")
setwd("/Users/yujung/Dropbox/Document/GitHub/bndovb/")
getwd()
devtools::document()
devtools::check()
devtools::build()
devtools::install(dependencies=FALSE)
